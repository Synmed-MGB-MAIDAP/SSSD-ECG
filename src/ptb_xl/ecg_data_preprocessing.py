from clinical_ts.timeseries_utils import *
from clinical_ts.ecg_utils import *
from pathlib import Path
import numpy as np
import os

threshold_version = "condition_bmi"

target_fs=100 # sampling rate (100 Hz or 500 Hz)
data_folder_ptb_xl = Path("/home/shared/physionet.org/files/ptb-xl/1.0.3")
target_folder_ptb_xl = Path(f"/home/shared/ptbxl_data_sssd-ecg/{threshold_version}") 

# v1 rough thresholds 90
thresholds_v1 = {
    "age": [30, 40, 50, 60, 70, 80],
    "weight": [60, 80, 100],
    "height": [160, 170, 180],
}
# percentile thresholds 92
thresholds_v2 = {
    "age": [42, 53, 60, 67, 75, 89],
    "weight": [57, 65, 73, 82],
    "height": [157, 163, 169, 175],
}

# common practive thresholds 91
thresholds_v3 = {
    "age": [12, 17, 34, 54, 74],
    "weight": [50, 70, 90, 110],
    "height": [150, 159, 169, 179],
}

# bmi thresholds 71+7
threshold_bmi = {
    "bmi": [18.5, 25, 30, 35, 40]
}

if threshold_version == "condition_v1":
    threshold_selected = thresholds_v1
elif threshold_version == "condition_v2":
    threshold_selected = thresholds_v2
elif threshold_version == "condition_v3":
    threshold_selected = thresholds_v3
elif threshold_version == "condition_bmi":
    threshold_selected = threshold_bmi

# Prepare the dataset
df_ptb_xl, lbl_itos_ptb_xl,  mean_ptb_xl, std_ptb_xl = prepare_data_ptb_xl(data_folder_ptb_xl, min_cnt=0, target_fs=target_fs, channels=12, channel_stoi=channel_stoi_default, target_folder=target_folder_ptb_xl, thresholds=threshold_selected)

print(lbl_itos_ptb_xl.keys())

#reformat everything as memmap for efficiency
reformat_as_memmap(df_ptb_xl, target_folder_ptb_xl/("memmap.npy"),data_folder=target_folder_ptb_xl,delete_npys=True)

df_ptb_xl.columns

# print the first dataline of the dataframe
df_ptb_xl.iloc[0]

# check all the columns and the datatypes
df_ptb_xl.dtypes

input_size = 1000  # Sample length

chunkify_train = False
chunk_length_train = input_size if chunkify_train else 0
stride_train = input_size
        
chunkify_valtest = False
chunk_length_valtest = input_size if chunkify_valtest else 0
stride_valtest = input_size

df_mapped, lbl_itos,  mean, std = load_dataset(target_folder_ptb_xl)
print("lbl_itos", lbl_itos.keys())
print(df_mapped.columns)

ds_mean = np.array([-0.00184586, -0.00130277,  0.00017031, -0.00091313, -0.00148835,  -0.00174687, -0.00077071, -0.00207407,  0.00054329,  0.00155546,  -0.00114379, -0.00035649])
ds_std = np.array([0.16401004, 0.1647168 , 0.23374124, 0.33767231, 0.33362807,  0.30583013, 0.2731171 , 0.27554379, 0.17128962, 0.14030828,   0.14606956, 0.14656108])

def multihot_encode(x, num_classes):
    res = np.zeros(num_classes,dtype=np.float32)
    for y in x:
        res[y]=1
    return res

# multiple labels
all_meta_labels = ['patient_id', 'age', 'sex', 'height', 'weight', 'nurse', 'site',
       'device', 'recording_date', 'report', 'scp_codes', 'heart_axis',
       'infarction_stadium1', 'infarction_stadium2', 'validated_by',
       'second_opinion', 'initial_autogenerated_report', 'validated_by_human',
       'baseline_drift', 'static_noise', 'burst_noise', 'electrodes_problems',
       'extra_beats', 'pacemaker', 'strat_fold', 'filename_lr', 'filename_hr',
       'label_all', 'label_diag', 'label_form', 'label_rhythm',
       'label_diag_subclass', 'label_diag_superclass', 'dataset',
       'label_all_numeric', 'label_diag_numeric', 'label_form_numeric',
       'label_rhythm_numeric', 'label_diag_subclass_numeric',
       'label_diag_superclass_numeric', 'data', 'data_mean', 'data_std',
       'data_length']

if "bmi" in threshold_selected:
    ptb_xl_label_demographcis = ["label_all", "label_bmi"]
else:
    ptb_xl_label_demographcis = ["label_all", "label_age", "label_sex", "label_height", "label_weight"]
# Label all has 71 classes, label age has 7 classes, label sex has 2 classes, label height has 5 classes, label weight has 5 classes

df_mapped["label"] = df_mapped.apply(
    lambda row: np.concatenate([
        multihot_encode(row[label+"_numeric"], len(lbl_itos[label]))
        for label in ptb_xl_label_demographcis
    ]),
    axis=1
)

# print(df_mapped["label"])
print(len(df_mapped["label"].iloc[0]))
tfms_ptb_xl_cpc = ToTensor()
            
max_fold_id = df_mapped.strat_fold.max()
print(df_mapped["strat_fold"].value_counts())

df_train = df_mapped[df_mapped.strat_fold<max_fold_id-1]
df_val = df_mapped[df_mapped.strat_fold==max_fold_id-1]
df_test = df_mapped[df_mapped.strat_fold==max_fold_id]

df_train["label"].iloc[0]

# Here are the PTB-XL dataloaders

ds_train=TimeseriesDatasetCrops(df_train,input_size,num_classes=len(lbl_itos),data_folder=target_folder_ptb_xl,chunk_length=chunk_length_train,min_chunk_length=input_size, stride=stride_train,transforms=tfms_ptb_xl_cpc,annotation=False,col_lbl ="label" ,memmap_filename=target_folder_ptb_xl/("memmap.npy"))
ds_val=TimeseriesDatasetCrops(df_val,input_size,num_classes=len(lbl_itos),data_folder=target_folder_ptb_xl,chunk_length=chunk_length_valtest,min_chunk_length=input_size, stride=stride_valtest,transforms=tfms_ptb_xl_cpc,annotation=False,col_lbl ="label",memmap_filename=target_folder_ptb_xl/("memmap.npy"))
ds_test=TimeseriesDatasetCrops(df_test,input_size,num_classes=len(lbl_itos),data_folder=target_folder_ptb_xl,chunk_length=chunk_length_valtest,min_chunk_length=input_size, stride=stride_valtest,transforms=tfms_ptb_xl_cpc,annotation=False,col_lbl ="label",memmap_filename=target_folder_ptb_xl/("memmap.npy"))

if not os.path.exists(target_folder_ptb_xl/"data"):
    print("Creating folders", target_folder_ptb_xl/"data")
    os.makedirs(target_folder_ptb_xl/"data")
if not os.path.exists(target_folder_ptb_xl/"labels"):
    print("Creating folders", target_folder_ptb_xl/"labels")
    os.makedirs(target_folder_ptb_xl/"labels")

# Save splits into npy files with data and labels
train_data_npy = []
train_label_npy = []
for i in range(len(ds_train)):
    train_data_npy.append(ds_train[i].data)
    train_label_npy.append(ds_train[i].label)
train_data_npy = np.array(train_data_npy)
trai_label_npy = np.array(train_label_npy)

np.save(target_folder_ptb_xl/"data/ptbxl_train_data.npy", train_data_npy)
np.save(target_folder_ptb_xl/"labels/ptbxl_train_labels.npy", train_label_npy)

val_data_npy = []
val_label_npy = []
for i in range(len(ds_val)):
    val_data_npy.append(ds_val[i].data)
    val_label_npy.append(ds_val[i].label)
val_data_npy = np.array(val_data_npy)
val_label_npy = np.array(val_label_npy)

np.save(target_folder_ptb_xl/"data/ptbxl_val_data.npy", val_data_npy)
np.save(target_folder_ptb_xl/"labels/ptbxl_val_labels.npy", val_label_npy)

test_data_npy = []
test_label_npy = []
for i in range(len(ds_test)):
    test_data_npy.append(ds_test[i].data)
    test_label_npy.append(ds_test[i].label)
test_data_npy = np.array(test_data_npy)
test_label_npy = np.array(test_label_npy)

np.save(target_folder_ptb_xl/"data/ptbxl_test_data.npy", test_data_npy)
np.save(target_folder_ptb_xl/"labels/ptbxl_test_labels.npy", test_label_npy)

# Load and check the shape of the saved npy files
train_data = np.load(target_folder_ptb_xl/"data/ptbxl_train_data.npy")
train_labels = np.load(target_folder_ptb_xl/"labels/ptbxl_train_labels.npy")
print(train_data.shape)
print(train_labels.shape)